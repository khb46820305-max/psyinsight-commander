"""
PsyInsight Commander - ë©”ì¸ Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜
ì‹¬ë¦¬í•™ ì „ë¬¸ê°€ë¥¼ ìœ„í•œ í†µí•© ëŒ€ì‹œë³´ë“œ
"""

import streamlit as st

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="PsyInsight Commander",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì œëª©
st.title("ğŸ§  PsyInsight Commander")
st.markdown("### ì‹¬ë¦¬ ì¸ì‚¬ì´íŠ¸ í†µí•© ì§€íœ˜ì†Œ")

# íƒ­ ìƒì„±
tab1, tab2, tab3 = st.tabs([
    "ğŸ“° Tab 1: ì‚¬ì´ì½œë¡œì§€ íŠ¸ëœë“œ ë ˆì´ë”",
    "ğŸ“š Tab 2: ì•„ì¹´ë°ë¯¹ ì•„ì¹´ì´ë¸Œ",
    "âœ¨ Tab 3: ì½˜í…ì¸  íŒ©í† ë¦¬"
])

# Tab 1: ì‚¬ì´ì½œë¡œì§€ íŠ¸ëœë“œ ë ˆì´ë”
with tab1:
    st.header("ğŸ“° ì‚¬ì´ì½œë¡œì§€ íŠ¸ëœë“œ ë ˆì´ë”")
    
    # ë‰´ìŠ¤ ìˆ˜ì§‘ ë²„íŠ¼
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown("ë¯¸êµ­ê³¼ í•œêµ­ì˜ ì‹¬ë¦¬ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  AIë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    with col2:
        if st.button("ğŸ”„ ë‰´ìŠ¤ ìˆ˜ì§‘", type="primary"):
            with st.spinner("ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                try:
                    from modules.news_collector import collect_and_analyze_news
                    collected, saved = collect_and_analyze_news(
                        keywords=["ì‹¬ë¦¬", "ë§ˆìŒê±´ê°•", "ë‡Œê³¼í•™", "ìƒë‹´"],
                        countries=["KR", "US"],
                        max_per_keyword=5
                    )
                    st.success(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {collected}ê°œ ìˆ˜ì§‘, {saved}ê°œ ì €ì¥")
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    # ë‰´ìŠ¤ ëª©ë¡ í‘œì‹œ
    st.divider()
    
    try:
        from modules.database import get_connection
        import json
        
        conn = get_connection()
        cursor = conn.cursor()
        
        # ê²€ìƒ‰ ë° í•„í„° ê¸°ëŠ¥
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            search_query = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì œëª©, ìš”ì•½, í‚¤ì›Œë“œë¡œ ê²€ìƒ‰...", key="news_search")
        
        with col2:
            sort_option = st.selectbox("ì •ë ¬", ["ìµœì‹ ìˆœ", "ì˜¤ë˜ëœìˆœ", "í‰ì  ë†’ì€ìˆœ", "í‰ì  ë‚®ì€ìˆœ"], key="news_sort")
        
        with col3:
            country_filter = st.selectbox("êµ­ê°€", ["ì „ì²´", "í•œêµ­", "ë¯¸êµ­"], key="news_country")
        
        # í‚¤ì›Œë“œ í•„í„° (í•´ì‹œíƒœê·¸)
        cursor.execute("SELECT DISTINCT keywords FROM articles WHERE keywords IS NOT NULL AND keywords != ''")
        all_keywords = set()
        for row in cursor.fetchall():
            try:
                keywords = json.loads(row[0]) if row[0] else []
                all_keywords.update(keywords)
            except:
                pass
        
        if all_keywords:
            selected_keywords = st.multiselect("ğŸ·ï¸ í‚¤ì›Œë“œ í•„í„°", sorted(all_keywords), key="news_keywords")
        else:
            selected_keywords = []
        
        # SQL ì¿¼ë¦¬ êµ¬ì„±
        where_conditions = []
        params = []
        
        # ê²€ìƒ‰ ì¡°ê±´
        if search_query:
            where_conditions.append("(title LIKE ? OR content_summary LIKE ? OR keywords LIKE ?)")
            search_param = f"%{search_query}%"
            params.extend([search_param, search_param, search_param])
        
        # êµ­ê°€ í•„í„°
        if country_filter != "ì „ì²´":
            where_conditions.append("country = ?")
            params.append("KR" if country_filter == "í•œêµ­" else "US")
        
        # í‚¤ì›Œë“œ í•„í„°
        if selected_keywords:
            keyword_conditions = []
            for keyword in selected_keywords:
                keyword_conditions.append("keywords LIKE ?")
                params.append(f'%"{keyword}"%')
            where_conditions.append(f"({' OR '.join(keyword_conditions)})")
        
        where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
        
        # ì •ë ¬
        if sort_option == "ìµœì‹ ìˆœ":
            order_by = "created_at DESC"
        elif sort_option == "ì˜¤ë˜ëœìˆœ":
            order_by = "created_at ASC"
        elif sort_option == "í‰ì  ë†’ì€ìˆœ":
            order_by = "validity_score DESC, created_at DESC"
        else:  # í‰ì  ë‚®ì€ìˆœ
            order_by = "validity_score ASC, created_at DESC"
        
        # í˜ì´ì§€ë„¤ì´ì…˜
        page_size = 10
        page = st.number_input("í˜ì´ì§€", min_value=1, value=1, step=1, key="news_page")
        offset = (page - 1) * page_size
        
        # ë‰´ìŠ¤ ì¡°íšŒ
        query = f"""
            SELECT id, date, title, url, content_summary, keywords, validity_score, country
            FROM articles
            WHERE {where_clause}
            ORDER BY {order_by}
            LIMIT ? OFFSET ?
        """
        params.extend([page_size, offset])
        
        cursor.execute(query, params)
        
        articles = cursor.fetchall()
        conn.close()
        
        if articles:
            st.markdown(f"### ğŸ“„ ë‰´ìŠ¤ ëª©ë¡ (ì´ {len(articles)}ê°œ í‘œì‹œ)")
            
            for article in articles:
                article_id, date, title, url, summary, keywords_json, score, country = article
                
                # í‚¤ì›Œë“œ íŒŒì‹±
                try:
                    keywords = json.loads(keywords_json) if keywords_json else []
                except:
                    keywords = []
                
                # ì¹´ë“œ í˜•íƒœë¡œ í‘œì‹œ
                with st.container():
                    col1, col2 = st.columns([4, 1])
                    
                    with col1:
                        st.markdown(f"#### {title}")
                        st.markdown(f"ğŸ“… {date} | ğŸŒ {country} | â­ {score}/5")
                        
                        if summary:
                            st.markdown(f"**ìš”ì•½:** {summary}")
                        
                        if keywords:
                            keyword_tags = " ".join([f"`{k}`" for k in keywords[:3]])
                            st.markdown(f"**í‚¤ì›Œë“œ:** {keyword_tags}")
                        
                        if url:
                            st.markdown(f"[ì›ë¬¸ ë³´ê¸° â†’]({url})")
                    
                    with col2:
                        # í‰ì  ì‹œê°í™”
                        st.markdown(f"### â­{score}")
                        st.progress(score / 5)
                    
                    st.divider()
        else:
            st.info("ğŸ“­ ì €ì¥ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ë‰´ìŠ¤ ìˆ˜ì§‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        st.info("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ 'ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")

# Tab 2: ì•„ì¹´ë°ë¯¹ ì•„ì¹´ì´ë¸Œ
with tab2:
    st.header("ğŸ“š ì•„ì¹´ë°ë¯¹ ì•„ì¹´ì´ë¸Œ")
    
    col1, col2 = st.columns([3, 1])
    with col1:
        st.markdown("ì‹¬ë¦¬í•™ ê´€ë ¨ ë…¼ë¬¸ì„ ìˆ˜ì§‘í•˜ê³  AIë¡œ ìš”ì•½í•©ë‹ˆë‹¤.")
    with col2:
        if st.button("ğŸ”„ ë…¼ë¬¸ ìˆ˜ì§‘", type="primary"):
            with st.spinner("ë…¼ë¬¸ ìˆ˜ì§‘ ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                try:
                    from modules.paper_collector import collect_and_analyze_papers
                    collected, saved = collect_and_analyze_papers(
                        keywords=["psychology", "counseling"],
                        sources=["arxiv"],
                        max_per_keyword=5
                    )
                    st.success(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {collected}ê°œ ìˆ˜ì§‘, {saved}ê°œ ì €ì¥")
                except Exception as e:
                    st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    st.divider()
    
    try:
        from modules.database import get_connection
        import json
        
        conn = get_connection()
        cursor = conn.cursor()
        
        # ê²€ìƒ‰ ë° í•„í„° ê¸°ëŠ¥
        col1, col2 = st.columns([2, 1])
        
        with col1:
            search_query = st.text_input("ğŸ” ê²€ìƒ‰", placeholder="ì œëª©, ì €ì, í‚¤ì›Œë“œë¡œ ê²€ìƒ‰...", key="paper_search")
        
        with col2:
            sort_option = st.selectbox("ì •ë ¬", ["ìµœì‹ ìˆœ", "ì˜¤ë˜ëœìˆœ"], key="paper_sort")
        
        # í‚¤ì›Œë“œ í•„í„°
        cursor.execute("SELECT DISTINCT keywords FROM papers WHERE keywords IS NOT NULL AND keywords != ''")
        all_keywords = set()
        for row in cursor.fetchall():
            try:
                keywords = json.loads(row[0]) if row[0] else []
                all_keywords.update(keywords)
            except:
                pass
        
        if all_keywords:
            selected_keywords = st.multiselect("ğŸ·ï¸ í‚¤ì›Œë“œ í•„í„°", sorted(all_keywords), key="paper_keywords")
        else:
            selected_keywords = []
        
        # SQL ì¿¼ë¦¬ êµ¬ì„±
        where_conditions = []
        params = []
        
        # ê²€ìƒ‰ ì¡°ê±´
        if search_query:
            where_conditions.append("(title LIKE ? OR authors LIKE ? OR keywords LIKE ?)")
            search_param = f"%{search_query}%"
            params.extend([search_param, search_param, search_param])
        
        # í‚¤ì›Œë“œ í•„í„°
        if selected_keywords:
            keyword_conditions = []
            for keyword in selected_keywords:
                keyword_conditions.append("keywords LIKE ?")
                params.append(f'%"{keyword}"%')
            where_conditions.append(f"({' OR '.join(keyword_conditions)})")
        
        where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
        
        # ì •ë ¬
        order_by = "created_at DESC" if sort_option == "ìµœì‹ ìˆœ" else "created_at ASC"
        
        # í˜ì´ì§€ë„¤ì´ì…˜
        page_size = 10
        page = st.number_input("í˜ì´ì§€", min_value=1, value=1, step=1, key="paper_page")
        offset = (page - 1) * page_size
        
        # ë…¼ë¬¸ ì¡°íšŒ
        query = f"""
            SELECT id, date, title, authors, journal, url, abstract, summary, keywords, category
            FROM papers
            WHERE {where_clause}
            ORDER BY {order_by}
            LIMIT ? OFFSET ?
        """
        params.extend([page_size, offset])
        
        cursor.execute(query, params)
        
        papers = cursor.fetchall()
        conn.close()
        
        if papers:
            st.markdown(f"### ğŸ“„ ë…¼ë¬¸ ëª©ë¡ (ì´ {len(papers)}ê°œ í‘œì‹œ)")
            
            for paper in papers:
                paper_id, date, title, authors_json, journal, url, abstract, summary_json, keywords_json, category = paper
                
                try:
                    authors = json.loads(authors_json) if authors_json else []
                    summary = json.loads(summary_json) if summary_json else {}
                    keywords = json.loads(keywords_json) if keywords_json else []
                except:
                    authors = []
                    summary = {}
                    keywords = []
                
                with st.container():
                    st.markdown(f"#### {title}")
                    st.markdown(f"ğŸ“… {date} | ğŸ“– {journal} | ğŸ·ï¸ {category}")
                    
                    if authors:
                        authors_str = ", ".join(authors[:3])
                        if len(authors) > 3:
                            authors_str += f" ì™¸ {len(authors) - 3}ëª…"
                        st.markdown(f"**ì €ì:** {authors_str}")
                    
                    if summary:
                        with st.expander("ğŸ“‹ ìš”ì•½ ë³´ê¸°"):
                            if summary.get("purpose"):
                                st.markdown(f"**ëª©ì :** {summary['purpose']}")
                            if summary.get("method"):
                                st.markdown(f"**ë°©ë²•:** {summary['method']}")
                            if summary.get("result"):
                                st.markdown(f"**ê²°ê³¼:** {summary['result']}")
                            if summary.get("implication"):
                                st.markdown(f"**ì‹œì‚¬ì :** {summary['implication']}")
                    
                    if abstract:
                        with st.expander("ğŸ“„ ì´ˆë¡ ë³´ê¸°"):
                            st.markdown(abstract[:500] + "..." if len(abstract) > 500 else abstract)
                    
                    if keywords:
                        keyword_tags = " ".join([f"`{k}`" for k in keywords[:3]])
                        st.markdown(f"**í‚¤ì›Œë“œ:** {keyword_tags}")
                    
                    if url:
                        st.markdown(f"[ì›ë¬¸ ë³´ê¸° â†’]({url})")
                    
                    st.divider()
        else:
            st.info("ğŸ“­ ì €ì¥ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì˜ 'ë…¼ë¬¸ ìˆ˜ì§‘' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë…¼ë¬¸ì„ ìˆ˜ì§‘í•˜ì„¸ìš”.")
            
    except Exception as e:
        st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì˜¤ë¥˜: {e}")

# Tab 3: ì½˜í…ì¸  íŒ©í† ë¦¬
with tab3:
    st.header("âœ¨ ì½˜í…ì¸  íŒ©í† ë¦¬")
    st.markdown("Tab 1~2ì—ì„œ ì„ íƒí•œ ì½˜í…ì¸ ë¥¼ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì¬ìƒì‚°í•©ë‹ˆë‹¤.")
    
    # ì„ íƒëœ ì½˜í…ì¸  í‘œì‹œ
    if 'selected_items' not in st.session_state:
        st.session_state.selected_items = []
    
    st.divider()
    
    # ì½˜í…ì¸  ì„ íƒ ì„¹ì…˜
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“° ë‰´ìŠ¤ ì„ íƒ")
        try:
            from modules.database import get_connection
            import json
            
            conn = get_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT id, title, content_summary FROM articles ORDER BY created_at DESC LIMIT 20")
            news_items = cursor.fetchall()
            conn.close()
            
            selected_news = []
            for item in news_items:
                if st.checkbox(f"ğŸ“° {item[1][:50]}...", key=f"news_{item[0]}"):
                    selected_news.append({"type": "news", "id": item[0], "title": item[1], "summary": item[2]})
        except Exception as e:
            st.error(f"ë‰´ìŠ¤ ë¡œë“œ ì˜¤ë¥˜: {e}")
            selected_news = []
    
    with col2:
        st.subheader("ğŸ“š ë…¼ë¬¸ ì„ íƒ")
        try:
            conn = get_connection()
            cursor = conn.cursor()
            cursor.execute("SELECT id, title, abstract FROM papers ORDER BY created_at DESC LIMIT 20")
            paper_items = cursor.fetchall()
            conn.close()
            
            selected_papers = []
            for item in paper_items:
                if st.checkbox(f"ğŸ“š {item[1][:50]}...", key=f"paper_{item[0]}"):
                    selected_papers.append({"type": "paper", "id": item[0], "title": item[1], "abstract": item[2]})
        except Exception as e:
            st.error(f"ë…¼ë¬¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
            selected_papers = []
    
    st.divider()
    
    # í…œí”Œë¦¿ ì„ íƒ
    st.subheader("ğŸ“ ì½˜í…ì¸  í…œí”Œë¦¿ ì„ íƒ")
    template = st.radio(
        "ìƒì„±í•  ì½˜í…ì¸  ìœ í˜•",
        ["ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸", "ë¦´ìŠ¤ ëŒ€ë³¸", "ê²Œì‹œê¸€", "ë…¼ë¬¸ ì•„ì´ë””ì–´"],
        horizontal=True
    )
    
    # ìƒì„± ë²„íŠ¼
    if st.button("âœ¨ ì½˜í…ì¸  ìƒì„±", type="primary", disabled=len(selected_news) + len(selected_papers) == 0):
        if len(selected_news) + len(selected_papers) == 0:
            st.warning("ì½˜í…ì¸ ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("AIê°€ ì½˜í…ì¸ ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    from modules.ai_engine import get_model
                    import google.generativeai as genai
                    
                    # ì„ íƒëœ ì½˜í…ì¸  ìš”ì•½
                    selected_content = []
                    for news in selected_news:
                        selected_content.append(f"ë‰´ìŠ¤: {news['title']}\n{news['summary']}")
                    for paper in selected_papers:
                        selected_content.append(f"ë…¼ë¬¸: {paper['title']}\n{paper['abstract'][:500]}")
                    
                    content_text = "\n\n".join(selected_content)
                    
                    # í…œí”Œë¦¿ë³„ í”„ë¡¬í”„íŠ¸
                    prompts = {
                        "ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸": f"""ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
êµ¬ì¡°: ì œëª©, ì„œë¡ , ë³¸ë¬¸(3-4ê°œ ì„¹ì…˜), ê²°ë¡ 

ì½˜í…ì¸ :
{content_text[:3000]}

ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸:""",
                        "ë¦´ìŠ¤ ëŒ€ë³¸": f"""ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ 30ì´ˆ ë¶„ëŸ‰ì˜ ë¦´ìŠ¤ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
êµ¬ì¡°: í›…(ì²« 3ì´ˆ ì£¼ëª©), ë³¸ë¬¸(í•µì‹¬ ë‚´ìš©), CTA(í–‰ë™ ìœ ë„)

ì½˜í…ì¸ :
{content_text[:2000]}

ë¦´ìŠ¤ ëŒ€ë³¸:""",
                        "ê²Œì‹œê¸€": f"""ë‹¤ìŒ ì½˜í…ì¸ ë¥¼ ë°”íƒ•ìœ¼ë¡œ SNSìš© ê²Œì‹œê¸€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
200ì ë‚´ì™¸, í•´ì‹œíƒœê·¸ í¬í•¨

ì½˜í…ì¸ :
{content_text[:2000]}

ê²Œì‹œê¸€:""",
                        "ë…¼ë¬¸ ì•„ì´ë””ì–´": f"""ë‹¤ìŒ ë…¼ë¬¸ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì—°êµ¬ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.
êµ¬ì¡°: ì—°êµ¬ ì£¼ì œ, ì—°êµ¬ ì§ˆë¬¸, ì˜ˆìƒ ë°©ë²•ë¡ , ì°¸ê³  ë…¼ë¬¸

ì½˜í…ì¸ :
{content_text[:3000]}

ë…¼ë¬¸ ì•„ì´ë””ì–´:"""
                    }
                    
                    model = get_model()
                    response = model.generate_content(
                        prompts[template],
                        generation_config={"temperature": 0.7, "max_output_tokens": 2000}
                    )
                    
                    generated_content = response.text
                    
                    st.success("âœ… ì½˜í…ì¸  ìƒì„± ì™„ë£Œ!")
                    st.markdown("### ìƒì„±ëœ ì½˜í…ì¸ ")
                    st.text_area("", generated_content, height=400)
                    
                    # ë³µì‚¬ ë²„íŠ¼
                    st.code(generated_content, language=None)
                    
                except Exception as e:
                    st.error(f"ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {e}")

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("âš™ï¸ ì„¤ì •")
    st.info("í”„ë¡œì íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"):
        try:
            from modules.database import init_database
            init_database()
            st.success("ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
